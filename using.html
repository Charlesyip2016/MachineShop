<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Using MachineShop</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MachineShop for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="using.html">Using</a>
</li>
<li>
  <a href="reference.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="example_info.html">Model and Metric Information</a>
    </li>
    <li>
      <a href="example_var_spec.html">Variable Specifications and Preprocessing</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="example_ichomes.html">IC Home Prices</a>
    </li>
    <li>
      <a href="example_iris.html">Iris Flowers Species</a>
    </li>
    <li>
      <a href="example_pima.html">Pima Indians Diabetes</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/brian-j-smith/MachineShop">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Using MachineShop</h1>

</div>


<div id="melanoma-example" class="section level1">
<h1>Melanoma Example</h1>
<p>The package is illustrated in the following sections with an overall survival analysis example in which the response variable is a time to event outcome. Since survival outcomes are a combination of numerical (time to event) and categorical (event) variables, package features for both variable types will be utilized in the example. Outcomes other than survival, including nominal and ordinal factors as well as numeric vectors and matrices, are supported by <code>MachineShop</code> and will be discussed.</p>
<p>Survival analysis is performed with the <code>Melanoma</code> dataset from the <code>MASS</code> package <span class="citation">(Andersen et al. 1993)</span>. This dataset provides survival time, in days, from disease treatment to (1) death from disease, (2) alive at end of study, or (3) death from other causes for 205 Denmark patients with malignant melanomas. Also provided are potential predictors of the survival outcomes. The analysis begins by loading required packages <code>MachineShop</code>, <code>survival</code>, and <code>MASS</code> as well as <code>magrittr</code> <span class="citation">(Bache and Wickham 2014)</span> for its pipe (<code>%&gt;%</code>) operator to simplify some of the code syntax. For the analysis, a binary overall survival outcome is created by combining the two death categories (1 and 3) into one. The dataset is then split into a training set on which a survival model will be fit and a test set on which predictions will be made. A global formula <code>surv_fo</code> is defined to relate the predictors on the right hand side to the overall survival outcome on the left and will be used in all of the survival models presented.</p>
<pre class="r"><code>## Analysis libraries
library(MachineShop)
library(survival)
library(MASS)
library(magrittr)

## Malignant melanoma analysis dataset
surv_df &lt;- within(Melanoma, status &lt;- as.numeric(status != 2))</code></pre>
<p>Descriptive summaries of the study variables are given below in Table 1, followed by a plot of estimated overall survival probabilities and 95% confidence intervals.</p>
<center>
Table 1. Variable summaries for the Melanoma survival analysis example.
</center>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Characteristic
</th>
<th style="text-align:center;">
Value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Number of subjects
</td>
<td style="text-align:center;">
205
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>time</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
2005 (10, 5565)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>status</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
1 = Dead
</td>
<td style="text-align:center;">
71 (34.63%)
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
0 = Alive
</td>
<td style="text-align:center;">
134 (65.37%)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>sex</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
1 = Male
</td>
<td style="text-align:center;">
79 (38.54%)
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
0 = Female
</td>
<td style="text-align:center;">
126 (61.46%)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>age</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
54 (4, 95)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>year</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
1970 (1962, 1977)
</td>
</tr>
<tr grouplength="1">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>thickness</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
Median (Range)
</td>
<td style="text-align:center;">
1.94 (0.10, 17.42)
</td>
</tr>
<tr grouplength="2">
<td colspan="2" style="border-bottom: 1px solid;">
<strong>ulcer</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
1 = Presence
</td>
<td style="text-align:center;">
90 (43.9%)
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
0 = Absence
</td>
<td style="text-align:center;">
115 (56.1%)
</td>
</tr>
</tbody>
</table>
<p><img src="using_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Training and test sets
set.seed(123)
train_indices &lt;- sample(nrow(surv_df), nrow(surv_df) * 2 / 3)
surv_train &lt;- surv_df[train_indices, ]
surv_test &lt;- surv_df[-train_indices, ]

## Global formula for the analysis
surv_fo &lt;- Surv(time, status) ~ sex + age + year + thickness + ulcer</code></pre>
</div>
<div id="model-fit-and-prediction" class="section level1">
<h1>Model Fit and Prediction</h1>
<div id="model-information" class="section level2">
<h2>Model Information</h2>
<p>Model fitting requires user specification of a <code>MachineShop</code> compatible model. A named list of package-supplied models can be obtained interactively with the <code>modelinfo</code> function, and includes the following components for each.</p>
<dl>
<dt><code>label</code></dt>
<dd>Character descriptor for the model.
</dd>
<dt><code>packages</code></dt>
<dd>Character vector of source packages required to use the model. These need only be installed with the <code>install.packages</code> function or by equivalent means; but need not be loaded with, for example, the <code>library</code> function.
</dd>
<dt><code>types</code></dt>
<dd>Character vector of response variable types supported by the model.
</dd>
<dt><code>arguments</code></dt>
<dd>Closure with the argument names and corresponding default values of the model function.
</dd>
<dt><code>grid</code></dt>
<dd>Logical indicating whether automatic generation of tuning parameter grids is implemented for the model.
</dd>
<dt><code>varimp</code></dt>
<dd>Logical indicating whether variable importance is defined for the model.
</dd>
</dl>
<p>Function <code>modelinfo</code> can be called with one or more model functions, function names, function calls, or observed response variables; and will return information on all models matching the calling arguments.</p>
<pre class="r"><code>## All available models
modelinfo() %&gt;% names
#&gt;  [1] &quot;AdaBagModel&quot;         &quot;AdaBoostModel&quot;       &quot;BARTModel&quot;          
#&gt;  [4] &quot;BARTMachineModel&quot;    &quot;BlackBoostModel&quot;     &quot;C50Model&quot;           
#&gt;  [7] &quot;CForestModel&quot;        &quot;CoxModel&quot;            &quot;CoxStepAICModel&quot;    
#&gt; [10] &quot;EarthModel&quot;          &quot;FDAModel&quot;            &quot;GAMBoostModel&quot;      
#&gt; [13] &quot;GBMModel&quot;            &quot;GLMBoostModel&quot;       &quot;GLMModel&quot;           
#&gt; [16] &quot;GLMStepAICModel&quot;     &quot;GLMNetModel&quot;         &quot;KNNModel&quot;           
#&gt; [19] &quot;LARSModel&quot;           &quot;LDAModel&quot;            &quot;LMModel&quot;            
#&gt; [22] &quot;MDAModel&quot;            &quot;NaiveBayesModel&quot;     &quot;NNetModel&quot;          
#&gt; [25] &quot;PDAModel&quot;            &quot;PLSModel&quot;            &quot;POLRModel&quot;          
#&gt; [28] &quot;QDAModel&quot;            &quot;RandomForestModel&quot;   &quot;RangerModel&quot;        
#&gt; [31] &quot;RPartModel&quot;          &quot;StackedModel&quot;        &quot;SuperModel&quot;         
#&gt; [34] &quot;SurvRegModel&quot;        &quot;SurvRegStepAICModel&quot; &quot;SVMModel&quot;           
#&gt; [37] &quot;SVMANOVAModel&quot;       &quot;SVMBesselModel&quot;      &quot;SVMLaplaceModel&quot;    
#&gt; [40] &quot;SVMLinearModel&quot;      &quot;SVMPolyModel&quot;        &quot;SVMRadialModel&quot;     
#&gt; [43] &quot;SVMSplineModel&quot;      &quot;SVMTanhModel&quot;        &quot;TreeModel&quot;          
#&gt; [46] &quot;XGBModel&quot;            &quot;XGBDARTModel&quot;        &quot;XGBLinearModel&quot;     
#&gt; [49] &quot;XGBTreeModel&quot;

## Survival-specific models
modelinfo(Surv(0)) %&gt;% names
#&gt;  [1] &quot;BARTModel&quot;           &quot;BlackBoostModel&quot;     &quot;CForestModel&quot;       
#&gt;  [4] &quot;CoxModel&quot;            &quot;CoxStepAICModel&quot;     &quot;GAMBoostModel&quot;      
#&gt;  [7] &quot;GBMModel&quot;            &quot;GLMBoostModel&quot;       &quot;GLMNetModel&quot;        
#&gt; [10] &quot;RangerModel&quot;         &quot;RPartModel&quot;          &quot;StackedModel&quot;       
#&gt; [13] &quot;SuperModel&quot;          &quot;SurvRegModel&quot;        &quot;SurvRegStepAICModel&quot;

## Model-specific information
modelinfo(GBMModel)
#&gt; $GBMModel
#&gt; $GBMModel$label
#&gt; [1] &quot;Generalized Boosted Regression&quot;
#&gt; 
#&gt; $GBMModel$packages
#&gt; [1] &quot;gbm&quot;
#&gt; 
#&gt; $GBMModel$types
#&gt; [1] &quot;factor&quot;  &quot;numeric&quot; &quot;Surv&quot;   
#&gt; 
#&gt; $GBMModel$arguments
#&gt; function (distribution = NULL, n.trees = 100, interaction.depth = 1, 
#&gt;     n.minobsinnode = 10, shrinkage = 0.1, bag.fraction = 0.5) 
#&gt; NULL
#&gt; 
#&gt; $GBMModel$grid
#&gt; [1] TRUE
#&gt; 
#&gt; $GBMModel$varimp
#&gt; [1] TRUE</code></pre>
<p>Information is displayed above for the <code>GBMModel</code> function which is a generalized boosted regression model — a tree-based ensemble method that can be applied to survival outcomes.</p>
</div>
<div id="fit-function" class="section level2">
<h2>Fit Function</h2>
<p>Package models, like <code>GBMModel</code>, can be specified in the <code>model</code> argument of the <code>fit</code> function to estimate a relationship (<code>surv_fo</code>) between predictors and an outcome based on a set of data (<code>surv_train</code>). Argument specifications may be in terms of the model function, function name, or a function call.</p>
<pre class="r"><code>## Generalized boosted regression fit

## Model function
surv_fit &lt;- fit(surv_fo, data = surv_train, model = GBMModel)

## Model function name
fit(surv_fo, data = surv_train, model = &quot;GBMModel&quot;)

## Model function call
fit(surv_fo, data = surv_train, model = GBMModel(n.trees = 100, interaction.depth = 1))</code></pre>
</div>
<div id="dynamic-model-parameters" class="section level2">
<h2>Dynamic Model Parameters</h2>
<p><em>Dynamic model parameters</em> are model function arguments defined as expressions to be evaluated at the time of model fitting. As such, their values can change based on the number of observations in the dataset supplied to the fit function. Expressions to dynamic parameters are specified within the package-supplied quote operator <code>.()</code> and can include the following objects:</p>
<dl>
<dt><code>nobs</code></dt>
<dd>number of observations in <code>data</code>.
</dd>
<dt><code>nvars</code></dt>
<dd>number of predictor variables in <code>data</code>.
</dd>
<dt><code>y</code></dt>
<dd>response variable.
</dd>
</dl>
<p>In the example below, Bayesian information criterion (BIC) based stepwise variable selection is performed by creating a <code>CoxStepAICModel</code> with dynamic parameter <code>k</code> to be calculated as the log number of observations in the fitted dataset.</p>
<pre class="r"><code>## Dynamic model parameter k = log number of observations

## Number of observations: nobs
fit(surv_fo, data = surv_df, model = CoxStepAICModel(k = .(log(nobs))))

## Response variable: y
fit (surv_fo, data = surv_df, model = CoxStepAICModel(k = .(log(length(y)))))</code></pre>
</div>
<div id="predict-function" class="section level2">
<h2>Predict Function</h2>
<p>A <code>predict</code> function is supplied for application to model fit results to obtain predicted values on a dataset specified with its <code>newdata</code> argument or on the original dataset if not specified. Survival means are predicted for survival outcomes by default. Estimates of the associated survival distributions are needed to calculate the means. For models, like <code>GBMModel</code>, that perform semi- or non-parametric survival analysis, Weibull approximations to the survival distributions are the default for mean estimation. Other choices of distributional approximations are exponential, Rayleigh, and empirical. Empirical distributions are applicable to Cox proportional hazards-based models and can be calculated with the method of Breslow <span class="citation">(1972)</span>, Efron <span class="citation">(1977, default)</span>, or Fleming and Harrington <span class="citation">(1984)</span>. Note, however, that empirical survival means are undefined mathematically if an event does not occur at the longest follow-up time. In such situations, a restricted survival mean is calculated by changing the longest follow-up time to an event, as suggested by Efron <span class="citation">(1967)</span>, which will be negatively biased.</p>
<pre class="r"><code>## Predicted survival means (default: Weibull distribution)
predict(surv_fit, newdata = surv_test) %&gt;% head
#&gt; [1]  8619.077 12395.758  3736.115  1332.317  1808.185  4202.563

## Predicted survival means (empirical distribution)
predict(surv_fit, newdata = surv_test, dist = &quot;empirical&quot;) %&gt;% head
#&gt; [1] 4098.222 4298.909 3269.318 1628.793 2123.959 3422.091</code></pre>
<p>In addition to survival means, predicted survival probabilities (<code>type = "prob"</code>) or 0-1 survival events (default: <code>type = "response"</code>) can be obtained with the follow-up <code>times</code> argument. The cutoff probability for classification of survival events (or other binary responses) can be set optionally with the <code>cutoff</code> argument (default: <code>cutoff = 0.5</code>). As with mean estimation, distributional approximations to the survival functions may be specified for the predictions, with the default for survival probabilities being the empirical distribution.</p>
<pre class="r"><code>## Predict survival probabilities and events at specified follow-up times
surv_times &lt;- 365 * c(5, 10)

predict(surv_fit, newdata = surv_test, times = surv_times, type = &quot;prob&quot;) %&gt;% head
#&gt; Object of class &quot;SurvProbs&quot;
#&gt;         Time 1     Time 2
#&gt; [1,] 0.8934348 0.79307877
#&gt; [2,] 0.9305378 0.86232916
#&gt; [3,] 0.7291876 0.52216086
#&gt; [4,] 0.3243167 0.09859702
#&gt; [5,] 0.4617520 0.20396307
#&gt; [6,] 0.7609545 0.57004119
#&gt; Attribute &quot;times&quot;:
#&gt; [1] 1825 3650

predict(surv_fit, newdata = surv_test, times = surv_times, cutoff = 0.5) %&gt;% head
#&gt; Object of class &quot;SurvEvents&quot;
#&gt;      Time 1 Time 2
#&gt; [1,]      0      0
#&gt; [2,]      0      0
#&gt; [3,]      0      0
#&gt; [4,]      1      1
#&gt; [5,]      1      1
#&gt; [6,]      0      0
#&gt; Attribute &quot;times&quot;:
#&gt; [1] 1825 3650</code></pre>
</div>
</div>
<div id="variable-specifications" class="section level1">
<h1>Variable Specifications</h1>
<p>Variable specification defines the relationship between response and predictor variables as well as the data used to estimate the relationship. Four main types of specifications are supported by the <code>fit</code>, <code>resample</code>, and <code>tune</code> functions: traditional formula, design matrix, model frame, and recipe.</p>
<div id="traditional-formula" class="section level2">
<h2>Traditional Formula</h2>
<p>Variables may be specified with a traditional formula and data frame pair, as was done at the start of the survival example. With this specification, formula operators, such as interaction (<code>:</code>), crossing (<code>*</code>), and deletion (<code>-</code>) as well as <code>.</code> substitution of variables not already appearing in the formula may be used.</p>
<pre class="r"><code>## Dataset library
library(MASS)

## Formula specification
fit(medv ~ ., data = Boston, model = GBMModel)</code></pre>
</div>
<div id="design-matrix" class="section level2">
<h2>Design Matrix</h2>
<p>Variables stored separately in a design matrix of predictors and object of responses can be supplied to the fit functions directly. Fitting with design matrices has less computational overhead than traditional formulas and allows for greater numbers of predictor variables in some models, including <code>GBMModel</code>, <code>GLMNetModel</code>, and <code>RandomForestModel</code>.</p>
<pre class="r"><code>## Example design matrix and response object
x &lt;- model.matrix(medv ~ . - 1, data = Boston)
y &lt;- Boston$medv

## Design matrix specification
fit(x, y, model = GBMModel)</code></pre>
</div>
<div id="model-frame" class="section level2">
<h2>Model Frame</h2>
<p>A <code>ModelFrame</code> class is provided by the package for specification of predictor and response variables along with other attributes to control model fitting. Model frames can be specified in calls to the <code>ModelFrame</code> constructor function with a syntax similar to the traditional formula or design matrix.</p>
<pre class="r"><code>## Model frame specification

## Formula
mf &lt;- ModelFrame(medv ~ ., data = Boston)

fit(mf, model = GBMModel)

## Design matrix
mf &lt;- ModelFrame(x, y)

fit(mf, model = GBMModel)</code></pre>
<p>The model frame approach has a few advantages over model fitting directly with a traditional formula. One is that cases with missing values on any of the response or predictor variables are excluded from the model frame by default. This is often desirable for models that do not handle missing values. Conversely, missing values can be retained in the model frame by setting its argument <code>na.rm = FALSE</code> for models, like <code>GBMModel</code>, that do handle them. A second advantage is that case weights can be included in the model frame to be passed on to the model fitting functions.</p>
<pre class="r"><code>## Model frame specification with case weights
mf &lt;- ModelFrame(ncases / (ncases + ncontrols) ~ agegp + tobgp + alcgp, data = esoph,
                 weights = with(esoph, ncases + ncontrols))

fit(mf, model = GBMModel)</code></pre>
<p>A third, which will be illustrated later, is user-specification of a variable for stratified resampling via the constructor’s <code>strata</code> argument.</p>
</div>
<div id="preprocessing-recipe" class="section level2">
<h2>Preprocessing Recipe</h2>
<p>The <code>recipes</code> package <span class="citation">(Kuhn and Wickham 2018)</span> provides a flexible framework for defining predictor and response variables as well as preprocessing steps to be applied to them prior to model fitting. Using recipes helps ensure that estimation of predictive performance accounts for all modeling step. They are also a convenient way of consistently applying preprocessing to new data. A basic recipe is given below in terms of the formula and data frame ingredients needed for the analysis.</p>
<pre class="r"><code>## Recipe specification
library(recipes)

rec &lt;- recipe(medv ~ ., data = Boston)

fit(rec, model = GBMModel)</code></pre>
<p>Case weights and stratified resampling are also supported for recipes via the designations of <code>"case_weight"</code> and <code>"case_strata"</code> roles, respectively.</p>
<pre class="r"><code>## Recipe specification with case weights
df &lt;- within(esoph, {
  y &lt;- ncases / (ncases + ncontrols)
  weights &lt;- ncases + ncontrols
})

rec &lt;- recipe(y ~ agegp + tobgp + alcgp + weights, data = df) %&gt;%
  update_role(weights, new_role = &quot;case_weight&quot;) %&gt;%
  step_ordinalscore(agegp, tobgp, alcgp)

fit(rec, model = GBMModel)</code></pre>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>The variable specification approaches differ with respect to support for preprocessing, in-line functions, case weights, resampling strata, and computational overhead, as summarized in the table below. Only recipes apply preprocessing steps automatically during model fitting and should be used when it is important to account for such steps in the estimation of model predictive performance. Preprocessing would have to be done manually and separately otherwise. Design matrices have the lowest computational overhead and can enable analyses involving larger numbers of predictors than the other approaches. Both recipes and model frames allow for user-defined case weights (default: equal) and resampling strata (default: none). The remaining approaches default to equal weights and to strata defined by the response variable. Syntax ranges from simplest to most complex for design matrices, traditional formulas, model frames, and recipes, respectively. The relative strengths of each approach should be considered within the context of a given analysis when deciding upon which one to use.</p>
<table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 2. Characteristics of available variable specification approaches.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Specification
</th>
<th style="text-align:center;">
Preprocessing
</th>
<th style="text-align:center;">
In-line Functions
</th>
<th style="text-align:center;">
Case Weights
</th>
<th style="text-align:center;">
Resampling Strata
</th>
<th style="text-align:center;">
Computational Overhead
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Traditional Formula
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">manual</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">yes</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">equal</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">response</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: blue;">medium</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Design Matrix
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">manual</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">no</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">equal</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">response</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">low</span>
</td>
</tr>
<tr grouplength="2">
<td colspan="6" style="border-bottom: 1px solid;">
<strong>Model Frame</strong>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold; padding-left: 2em;" indentlevel="1">
Traditional Formula
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">manual</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">yes</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: blue;">medium</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold; padding-left: 2em;" indentlevel="1">
Design Matrix
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">manual</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">no</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">low</span>
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Recipe
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">automatic</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">no</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: green;">user</span>
</td>
<td style="text-align:center;">
<span style="     color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;">high</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="response-variable-types" class="section level1">
<h1>Response Variable Types</h1>
<p>The R class types of response variables play a central role in their analysis with the package. They determine, for example, the specific models that can be fit, fitting algorithms employed, predicted values produced, and applicable performance metrics and analyses. As described below, factors, ordered factors, numeric vectors and matrices, and survival responses are supported by the package.</p>
<div id="factors" class="section level2">
<h2>Factors</h2>
<p>Categorical responses with two or more levels should be coded as <code>factor</code> variables for analysis.</p>
<pre class="r"><code>## Iris flowers species (3-level factor)
fit(Species ~ ., data = iris, model = GBMModel)</code></pre>
<pre class="r"><code>## Pima Indians diabetes statuses (binary factor)
library(MASS)

fit(type ~ ., data = Pima.tr, model = GBMModel)</code></pre>
</div>
<div id="ordered-factors" class="section level2">
<h2>Ordered Factors</h2>
<p>Ordinal categorical responses should be coded as <code>ordered</code> factor variables. For categorical vectors, this can be accomplished with the <code>factor</code> function and its argument <code>ordered = TRUE</code> or more simply with the <code>ordered</code> function. Numeric vectors can be converted to ordered factors with the <code>cut</code> function.</p>
<pre class="r"><code>## Boston housing prices (ordered factor)
library(MASS)

df &lt;- within(Boston, {
  medv &lt;- cut(medv, breaks = 3, ordered_result = TRUE)
})

fit(medv ~ ., data = df, model = GBMModel)</code></pre>
</div>
<div id="numeric-vectors" class="section level2">
<h2>Numeric Vectors</h2>
<p>Univariate numerical responses should be coded as <code>numeric</code> variables.</p>
<pre class="r"><code>## Boston housing prices
library(MASS)

fit(medv ~ ., data = Boston, model = GBMModel)</code></pre>
</div>
<div id="numeric-matrices" class="section level2">
<h2>Numeric Matrices</h2>
<p>Multivariate numerical responses should be given as numeric <code>matrix</code> variables for model fitting with traditional formulas or model frames.</p>
<pre class="r"><code>## Anscombe&#39;s multiple regression models dataset

## Numeric matrix response formula
fit(cbind(y1, y2, y3) ~ x1, data = anscombe, model = LMModel)</code></pre>
<p>For recipes, the multiple response variables should be given on the left hand side of the formula specification.</p>
<pre class="r"><code>## Numeric matrix response recipe
rec &lt;- recipe(y1 + y2 + y3 ~ x1, data = anscombe)

fit(rec, model = LMModel)</code></pre>
</div>
<div id="survival-objects" class="section level2">
<h2>Survival Objects</h2>
<p>Survival responses should be coded as <code>Surv</code> variables for model fitting with traditional formulas or model frames.</p>
<pre class="r"><code>## Survival response formula
library(survival)

fit(Surv(time, status) ~ ., data = surv_df, model = GBMModel)</code></pre>
<p>For recipes, survival outcomes should be specified with the individual survival time and event variables given on the left hand side of the formula and with their roles designated as <code>"surv_time"</code> and <code>"surv_event"</code>.</p>
<pre class="r"><code>## Survival response recipe
rec &lt;- recipe(time + status ~ ., data = surv_df) %&gt;%
  add_role(time, new_role = &quot;surv_time&quot;) %&gt;%
  add_role(status, new_role = &quot;surv_event&quot;)

fit(rec, model = GBMModel)</code></pre>
</div>
</div>
<div id="model-performance-metrics" class="section level1">
<h1>Model Performance Metrics</h1>
<div id="performance-function" class="section level2">
<h2>Performance Function</h2>
<p>Performance metrics quantify associations between observed and predicted responses and provide a means of assessing and comparing the predictive performances of models. Metrics can be computed with the <code>performance</code> function applied to observed responses and responses predicted with the <code>predict</code> function. In the case of observed versus predicted survival probabilities or events, metrics will be calculated at each survival time and returned along with their time-integrated mean.</p>
<pre class="r"><code>## Survival performance metrics

## Observed responses
obs &lt;- response(surv_fit, newdata = surv_test)

## Predicted survival means
pred_means &lt;- predict(surv_fit, newdata = surv_test)
performance(obs, pred_means)
#&gt;    CIndex 
#&gt; 0.6414234

## Predicted survival probabilities
pred_probs &lt;- predict(surv_fit, newdata = surv_test, times = surv_times, type = &quot;prob&quot;)
performance(obs, pred_probs)
#&gt;     Brier.mean    Brier.time1    Brier.time2    ROCAUC.mean   ROCAUC.time1 
#&gt;      0.2223704      0.1901665      0.2545743      0.6304049      0.6634101 
#&gt;   ROCAUC.time2  Accuracy.mean Accuracy.time1 Accuracy.time2 
#&gt;      0.5973996      0.6817370      0.7607143      0.6027596

## Predicted survival events
pred_events &lt;- predict(surv_fit, newdata = surv_test, times = surv_times)
performance(obs, pred_events)
#&gt;  Accuracy.mean Accuracy.time1 Accuracy.time2 
#&gt;      0.6817370      0.7607143      0.6027596</code></pre>
<p>Function <code>performance</code> computes a default set of metrics according to the observed and predicted response types, as indicated in the table below.</p>
<p>Table 3. Default performance metrics by response types.</p>
<table>
<colgroup>
<col width="30%" />
<col width="69%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Response</th>
<th align="left">Default Metrics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Factor</td>
<td align="left">Brier Score, Accuracy, Cohen’s Kappa</td>
</tr>
<tr class="even">
<td align="left">Binary Factor</td>
<td align="left">Brier Score, Accuracy, Cohen’s Kappa, Area Under ROC Curve, Sensitivity, Specificity</td>
</tr>
<tr class="odd">
<td align="left">Numeric Vector or Matrix</td>
<td align="left">Root Mean Squared Error, R<sup>2</sup>, Mean Absolute Error</td>
</tr>
<tr class="even">
<td align="left">Survival Means</td>
<td align="left">Concordance Index</td>
</tr>
<tr class="odd">
<td align="left">Survival Probabilities</td>
<td align="left">Area Under ROC Curve, Brier Score, Accuracy</td>
</tr>
<tr class="even">
<td align="left">Survival Events</td>
<td align="left">Accuracy</td>
</tr>
</tbody>
</table>
<p>These defaults may be changed by specifying one or more package-supplied metric functions to the <code>metrics</code> argument of <code>performance</code>. Specification of the <code>metrics</code> argument can be in terms of a single metric function, function name, or list of metric functions. List names, if specified, will be displayed as metric labels in graphical and tabular summaries; otherwise, the function names will be used as labels for unnamed lists.</p>
<pre class="r"><code>## Single metric function
performance(obs, pred_means, metrics = cindex)

## Single metric function name
performance(obs, pred_means, metrics = &quot;cindex&quot;)

## List of metric functions
performance(obs, pred_means, metrics = c(cindex, rmse, rmsle))

## Named list of metric functions
performance(obs, pred_means, metrics = c(&quot;CIndex&quot; = cindex,
                                         &quot;RMSE&quot; = rmse,
                                         &quot;RMSLE&quot; = rmsle))</code></pre>
<p>Metrics based on classification of two-level class probabilities, like sensitivity and specificity, optionally allow for specification of the classification cutoff probability (default: <code>cutoff = 0.5</code>).</p>
<pre class="r"><code>## User-specified survival probability metrics
performance(obs, pred_probs, metrics = c(sensitivity, specificity), cutoff = 0.5)
#&gt;  sensitivity.mean sensitivity.time1 sensitivity.time2  specificity.mean 
#&gt;         0.4210721         0.3997553         0.4423889         0.8033254 
#&gt; specificity.time1 specificity.time2 
#&gt;         0.8834709         0.7231799</code></pre>
</div>
<div id="metric-information" class="section level2">
<h2>Metric Information</h2>
<p>A named list of supplied metrics can be obtained interactively with the <code>metricinfo</code> function, and includes the following components for each.</p>
<dl>
<dt><code>label</code></dt>
<dd>Character descriptor for the metric.
</dd>
<dt><code>maximize</code></dt>
<dd>Logical indicating whether higher values of the metric correspond to better predictive performance.
</dd>
<dt><code>arguments</code></dt>
<dd>Closure with the argument names and corresponding default values of the metric function.
</dd>
<dt><code>types</code></dt>
<dd>Data frame of the observed and predicted response variable types supported by the metric.
</dd>
</dl>
<p>Function <code>metricinfo</code> may be called with one or more metric functions, function names, an observed response variable, or an observed and predicted response variable pair; and will return information on all matching metrics.</p>
<pre class="r"><code>## Names of all available metrics
metricinfo() %&gt;% names
#&gt;  [1] &quot;accuracy&quot;        &quot;auc&quot;             &quot;brier&quot;          
#&gt;  [4] &quot;cindex&quot;          &quot;cross_entropy&quot;   &quot;f_score&quot;        
#&gt;  [7] &quot;fnr&quot;             &quot;fpr&quot;             &quot;gini&quot;           
#&gt; [10] &quot;kappa2&quot;          &quot;mae&quot;             &quot;mse&quot;            
#&gt; [13] &quot;msle&quot;            &quot;npv&quot;             &quot;ppv&quot;            
#&gt; [16] &quot;pr_auc&quot;          &quot;precision&quot;       &quot;r2&quot;             
#&gt; [19] &quot;recall&quot;          &quot;rmse&quot;            &quot;rmsle&quot;          
#&gt; [22] &quot;roc_auc&quot;         &quot;roc_index&quot;       &quot;rpp&quot;            
#&gt; [25] &quot;sensitivity&quot;     &quot;specificity&quot;     &quot;tnr&quot;            
#&gt; [28] &quot;tpr&quot;             &quot;weighted_kappa2&quot;

## Metrics for observed and predicted response variables
metricinfo(obs, pred_means) %&gt;% names
#&gt; [1] &quot;cindex&quot; &quot;gini&quot;   &quot;mae&quot;    &quot;mse&quot;    &quot;msle&quot;   &quot;r2&quot;     &quot;rmse&quot;   &quot;rmsle&quot;
metricinfo(obs, pred_probs) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;f_score&quot;     &quot;fnr&quot;        
#&gt;  [6] &quot;fpr&quot;         &quot;kappa2&quot;      &quot;npv&quot;         &quot;ppv&quot;         &quot;pr_auc&quot;     
#&gt; [11] &quot;precision&quot;   &quot;recall&quot;      &quot;roc_auc&quot;     &quot;roc_index&quot;   &quot;rpp&quot;        
#&gt; [16] &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

## Metrics for response variable types
metricinfo(Surv(0), numeric(0)) %&gt;% names
#&gt; [1] &quot;cindex&quot; &quot;gini&quot;   &quot;mae&quot;    &quot;mse&quot;    &quot;msle&quot;   &quot;r2&quot;     &quot;rmse&quot;   &quot;rmsle&quot;
metricinfo(Surv(0), SurvProbs(0)) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;f_score&quot;     &quot;fnr&quot;        
#&gt;  [6] &quot;fpr&quot;         &quot;kappa2&quot;      &quot;npv&quot;         &quot;ppv&quot;         &quot;pr_auc&quot;     
#&gt; [11] &quot;precision&quot;   &quot;recall&quot;      &quot;roc_auc&quot;     &quot;roc_index&quot;   &quot;rpp&quot;        
#&gt; [16] &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

## Metric-specific information
metricinfo(cindex)
#&gt; $cindex
#&gt; $cindex$label
#&gt; [1] &quot;Concordance Index&quot;
#&gt; 
#&gt; $cindex$maximize
#&gt; [1] TRUE
#&gt; 
#&gt; $cindex$arguments
#&gt; function (observed, predicted = NULL, ...) 
#&gt; NULL
#&gt; 
#&gt; $cindex$types
#&gt;   observed predicted
#&gt; 1   factor   numeric
#&gt; 2     Surv   numeric</code></pre>
</div>
<div id="factors-1" class="section level2">
<h2>Factors</h2>
<p>Metrics applicable to multi-level factor response variables are summarized below.</p>
<dl>
<dt><code>accuracy</code></dt>
<dd>Proportion of correctly classified responses.
</dd>
<dt><code>brier</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>.
</dd>
<dt><code>cross_entropy</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Cross_entropy">Cross entropy</a> loss averaged over the number of cases.
</dd>
<dt><code>kappa2</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen’s kappa</a> statistic measuring relative agreement between observed and predicted classifications.
</dd>
<dt><code>weighted_kappa2</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa#Weighted_kappa">Weighted Cohen’s kappa</a>. This metric is only available for ordered factor responses.
</dd>
</dl>
<p>Brier score and cross entropy loss are computed directly on predicted class probabilities. The other metrics are computed on predicted class membership, defined as the factor level with the highest predicted probability.</p>
</div>
<div id="binary-factors" class="section level2">
<h2>Binary Factors</h2>
<p>Metrics for binary factors include those given for multi-level factors as well as the following.</p>
<dl>
<dt><code>auc</code></dt>
<dd>Area under a performance curve.
</dd>
<dt><code>cindex</code></dt>
<dd>Concordance index computed as rank order agreement between predicted probabilities for paired event and non-event cases. This metric can be interpreted as the probability that a randomly selected event case will have a higher predicted value than a randomly selected non-event case, and is the same as area under the ROC curve.
</dd>
<dt><code>f_score</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Precision_and_recall#F-measure">F score</a>, <span class="math inline">\(F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \times \text{precision} + \text{recall}}\)</span>. F1 score <span class="math inline">\((\beta = 1)\)</span> is the package default.
</dd>
<dt><code>fnr</code></dt>
<dd>False negative rate, <span class="math inline">\(FNR = \frac{FN}{TP + FN} = 1 - TPR\)</span>.
</dd>
</dl>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 4. Confusion matrix of observed and predicted response classifications.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Predicted Response
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observed Response
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Negative
</th>
<th style="text-align:center;">
Positive
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Negative
</td>
<td style="text-align:center;">
True Negative (TN)
</td>
<td style="text-align:center;">
False Negative (FN)
</td>
</tr>
<tr>
<td style="text-align:left;">
Positive
</td>
<td style="text-align:center;">
False Positive (FP)
</td>
<td style="text-align:center;">
True Positive (TP)
</td>
</tr>
</tbody>
</table>
<dl>
<dt><code>fpr</code></dt>
<dd>False positive rate, <span class="math inline">\(FPR = \frac{FP}{TN + FP} = 1 - TNR\)</span>.
</dd>
<dt><code>npv</code></dt>
<dd>Negative predictive value, <span class="math inline">\(NPV = \frac{TN}{TN + FN}\)</span>.
</dd>
<dt><code>ppv</code>, <code>precision</code></dt>
<dd>Positive predictive value, <span class="math inline">\(PPV = \frac{TP}{TP + FP}\)</span>.
</dd>
<dt><code>pr_auc</code>, <code>auc</code></dt>
<dd>Area under a precision recall curve.
</dd>
<dt><code>roc_auc</code>, <code>auc</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">Area under an ROC curve</a>.
</dd>
<dt><code>roc_index</code></dt>
<dd>A tradeoff function of sensitivity and specificity as defined by the <code>f</code> argument in this function (default: sensitivity + specificity). The function allows for specification of tradeoffs <span class="citation">(Perkins and Schisterman 2006)</span> other than the default of Youden’s J statistic <span class="citation">(Youden 1950)</span>.
</dd>
<dt><code>rpp</code></dt>
<dd>Rate of positive prediction, <span class="math inline">\(RPP = \frac{TP + FP}{TP + FP + TN + FN}\)</span>.
</dd>
<dt><code>sensitivity</code>, <code>recall</code>, <code>tpr</code></dt>
<dd>True positive rate, <span class="math inline">\(TPR =\frac{TP}{TP + FN} = 1 - FNR\)</span>.
</dd>
<dt><code>specificity</code>, <code>tnr</code></dt>
<dd>True negative rate, <span class="math inline">\(TNR = \frac{TN}{TN + FP} = 1 - FPR\)</span>.
</dd>
</dl>
<p>Area under the ROC and precision-recall curves as well as the concordance index are computed directly on predicted class probabilities. The other metrics are computed on predicted class membership. Memberships are defined to be in the second factor level if predicted probabilities are greater than the cutoff value set in the <code>performance</code> function.</p>
</div>
<div id="numerics" class="section level2">
<h2>Numerics</h2>
<p>Performance metrics are defined below for numeric vector responses. If applied to a numeric matrix response, the metrics are computed separately for each column and then averaged to produce a single value.</p>
<dl>
<dt><code>gini</code></dt>
<dd><a href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini coefficient</a>.
</dd>
<dt><code>mae</code></dt>
<dd>Mean absolute error, <span class="math inline">\(MAE = \frac{1}{n}\sum_{i=1}^n|y_i - \hat{y}_i|\)</span>, where <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\hat{y}_i\)</span> are the <span class="math inline">\(n\)</span> observed and predicted responses.
</dd>
<dt><code>mse</code></dt>
<dd>Mean squared error, <span class="math inline">\(MSE = \frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2\)</span>.
</dd>
<dt><code>msle</code></dt>
<dd>Mean squared log error, <span class="math inline">\(MSLE = \frac{1}{n}\sum_{i=1}^n(log(1 + y_i) - log(1 + \hat{y}_i))^2\)</span>.
</dd>
<dt><code>r2</code></dt>
<dd>One minus residual divided by total sums of squares, <span class="math inline">\(R^2 = 1 - \sum_{i=1}^n(y_i - \hat{y}_i)^2 / \sum_{i=1}^n(y_i - \bar{y})^2\)</span>.
</dd>
<dt><code>rmse</code></dt>
<dd>Square root of mean squared error.
</dd>
<dt><code>rmsle</code></dt>
<dd>Square root of mean squared log error.
</dd>
</dl>
</div>
<div id="survival-objects-1" class="section level2">
<h2>Survival Objects</h2>
<p>All previously described metrics for binary factor responses—plus accuracy, Brier score and Cohen’s kappa—are applicable to survival probabilities predicted at specified follow-up times. Metrics are evaluated separately at each follow-up time and reported along with a time-integrated mean. The survival concordance index is computed with the method of Harrell <span class="citation">(1982)</span> and Brier score according to Graf et al. <span class="citation">(1999)</span>; whereas, the others are computed according to the confusion matrix probabilities below, in which term <span class="math inline">\(\hat{S}(t)\)</span> is the predicted survival probability at follow-up time <span class="math inline">\(t\)</span> and <span class="math inline">\(T\)</span> is the survival time <span class="citation">(Heagerty, Lumley, and Pepe 2004)</span>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Table 5. Confusion matrix of observed and predicted survival response classifications.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Predicted Response
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Observed Response
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Non-Event
</th>
<th style="text-align:center;">
Event
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Non-Event
</td>
<td style="text-align:center;">
<span class="math inline">\(TN = \Pr(\hat{S}(t) \gt \text{cutoff} \cap T \ge t)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(FN = \Pr(\hat{S}(t) \gt \text{cutoff} \cap T \lt t)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Event
</td>
<td style="text-align:center;">
<span class="math inline">\(FP = \Pr(\hat{S}(t) \le \text{cutoff} \cap T \ge t)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(TP = \Pr(\hat{S}(t) \le \text{cutoff} \cap T \lt t)\)</span>
</td>
</tr>
</tbody>
</table>
<p>In addition, all of the metrics described for numeric vector responses are applicable to predicted survival means and are computed using only those cases with observed (non-censored) events.</p>
</div>
</div>
<div id="resample-performance-estimation" class="section level1">
<h1>Resample Performance Estimation</h1>
<div id="algorithms" class="section level2">
<h2>Algorithms</h2>
<p>Model performance can be estimated with resampling methods that simulate repeated training and test set fits and predictions. With these methods, performance metrics are computed on each resample to produce an empirical distribution for inference. Resampling is controlled in the <code>MachineShop</code> with the functions:</p>
<dl>
<dt>BootControl</dt>
<dd>Simple bootstrap resampling. Models are repeatedly fit with bootstrap resampled training sets and used to predict the full data set.
</dd>
<dt>CVControl</dt>
<dd>Repeated K-fold cross-validation. The full data set is repeatedly partitioned into K-folds. For a given partitioning, prediction is performed on each of the K folds with models fit on all remaining folds.
</dd>
<dt>OOBControl</dt>
<dd>Out-of-bootstrap resampling. Models are fit with bootstrap resampled training sets and used to predict the unsampled cases.
</dd>
<dt>SplitControl</dt>
<dd>Split training and test sets. The data are randomly partitioned into a training and test set.
</dd>
<dt>TrainControl</dt>
<dd>Training resubstitution. A model is fit on and used to predict the full training set in order to estimate training, or apparent, error.
</dd>
</dl>
<p>For the survival example, repeated cross-validation control structures are defined to estimate model performance in predicting survival means and 5 and 10-year survival probabilities. In addition to arguments controlling the resampling algorithms, a <code>seed</code> can be set to ensure reproducibility of resampling results obtained with the structures.</p>
<pre class="r"><code>## Control parameters for K-fold cross-validation

## Prediction of survival means
surv_means_control &lt;- CVControl(folds = 5, repeats = 3, seed = 123)

## Prediction of survival probabilities
surv_probs_control &lt;- CVControl(folds = 5, repeats = 3, times = surv_times, seed = 123)</code></pre>
</div>
<div id="parallel-processing" class="section level2">
<h2>Parallel Processing</h2>
<p>Resampling is implemented with the <code>foreach</code> package <span class="citation">(Microsoft and Weston 2017)</span> and will run in parallel if a compatible backend is loaded, such as that provided by the <code>doParallel</code> package <span class="citation">(Microsoft and Weston 2018)</span>.</p>
<pre class="r"><code>## Register multiple cores for parallel computations
library(doParallel)
registerDoParallel(cores = 2)</code></pre>
</div>
<div id="resample-function" class="section level2">
<h2>Resample Function</h2>
<p>Resampling is performed by calling the <code>resample</code> function with a variable specification, model, and control structure. Like the <code>fit</code> function, variables may be specified in terms of a traditional formula, design matrix, model frame, or recipe. Summary statistics and plots of resample output can be obtained with the <code>summary</code> and <code>plot</code> functions.</p>
<pre class="r"><code>## Resample estimation for survival means and probabilities
(res_means &lt;- resample(surv_fo, data = surv_df, model = GBMModel, control = surv_means_control))
#&gt; Object of class &quot;Resamples&quot;
#&gt; 
#&gt; Models: GBMModel
#&gt; Stratification variable: (strata) 
#&gt; 
#&gt; Object of class &quot;MLControl&quot;
#&gt; 
#&gt; Name: CVControl
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3
#&gt; Seed: 123

(res_probs &lt;- resample(surv_fo, data = surv_df, model = GBMModel, control = surv_probs_control))
#&gt; Object of class &quot;Resamples&quot;
#&gt; 
#&gt; Models: GBMModel
#&gt; Stratification variable: (strata) 
#&gt; 
#&gt; Object of class &quot;MLControl&quot;
#&gt; 
#&gt; Name: CVControl
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3
#&gt; Survival times: 1825, 3650
#&gt; Seed: 123

summary(res_probs)
#&gt;                     Mean    Median         SD       Min       Max NA
#&gt; Brier.mean     0.2142683 0.2209187 0.02535889 0.1651204 0.2510655  0
#&gt; Brier.time1    0.1865732 0.1931616 0.03231917 0.1390596 0.2395902  0
#&gt; Brier.time2    0.2419634 0.2328018 0.05029385 0.1856179 0.3554228  0
#&gt; ROCAUC.mean    0.7003126 0.6784924 0.06065723 0.6241044 0.8151629  0
#&gt; ROCAUC.time1   0.7269430 0.7142815 0.08019011 0.5933010 0.8597839  0
#&gt; ROCAUC.time2   0.6736821 0.6699859 0.06283310 0.5786972 0.7795556  0
#&gt; Accuracy.mean  0.6903808 0.6688471 0.04750030 0.6288628 0.8034240  0
#&gt; Accuracy.time1 0.7580823 0.7560976 0.06087687 0.6354739 0.8536585  0
#&gt; Accuracy.time2 0.6226792 0.6405024 0.09247024 0.4611556 0.7848968  0

plot(res_probs)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-42-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The <code>summary</code> function when applied directly to output from <code>resample</code> computes default performance metrics as described in the <em>Performance Function</em> section. Likewise, the <code>metricinfo</code> and <code>performance</code> functions can be applied to the output in order to list and compute applicable metrics.</p>
<pre class="r"><code>## Resample-specific metrics
metricinfo(res_probs) %&gt;% names
#&gt;  [1] &quot;accuracy&quot;    &quot;auc&quot;         &quot;brier&quot;       &quot;f_score&quot;     &quot;fnr&quot;        
#&gt;  [6] &quot;fpr&quot;         &quot;kappa2&quot;      &quot;npv&quot;         &quot;ppv&quot;         &quot;pr_auc&quot;     
#&gt; [11] &quot;precision&quot;   &quot;recall&quot;      &quot;roc_auc&quot;     &quot;roc_index&quot;   &quot;rpp&quot;        
#&gt; [16] &quot;sensitivity&quot; &quot;specificity&quot; &quot;tnr&quot;         &quot;tpr&quot;

## User-specified survival probability metrics
summary(performance(res_probs, metrics = c(sensitivity, specificity)))
#&gt;                        Mean    Median         SD        Min       Max NA
#&gt; sensitivity.mean  0.3998915 0.3549009 0.11023028 0.24838040 0.5680265  0
#&gt; sensitivity.time1 0.3260253 0.2727273 0.14462166 0.07513094 0.6250000  0
#&gt; sensitivity.time2 0.4737578 0.4857975 0.15010903 0.23675694 0.7295489  0
#&gt; specificity.mean  0.8366948 0.8493977 0.06465966 0.70274111 0.9265623  0
#&gt; specificity.time1 0.9195801 0.9321153 0.05598331 0.76550868 1.0000000  0
#&gt; specificity.time2 0.7538094 0.7484976 0.09435790 0.58759190 0.9158697  0</code></pre>
</div>
<div id="stratified-resampling" class="section level2">
<h2>Stratified Resampling</h2>
<p>Stratification of cases for the construction of resampled training and test sets can be employed to help achieve balance across the sets. Stratified resampling is automatically performed if variable specification is in terms of a traditional formula and will be done according to the response variable if a numeric vector or factor, the event variable if survival, and the first variable if a numeric matrix. For model frames and recipes, stratification variables must be defined explicitly with the <code>strata</code> argument to the <code>ModelFrame</code> constructor or with the <code>"case_strata"</code> role designation in a recipe step.</p>
<pre class="r"><code>## Model frame with case status stratification
mf &lt;- ModelFrame(surv_fo, data = surv_df, strata = surv_df$status)

resample(mf, model = GBMModel)

## Recipe with case status stratification
rec &lt;- recipe(time + status ~ ., data = surv_df) %&gt;%
  add_role(time, new_role = &quot;surv_time&quot;) %&gt;%
  add_role(status, new_role = &quot;surv_event&quot;) %&gt;%
  add_role(status, new_role = &quot;case_strata&quot;)

resample(rec, model = GBMModel)</code></pre>
</div>
<div id="dynamic-model-parameters-1" class="section level2">
<h2>Dynamic Model Parameters</h2>
<p>As discussed previously in the <em>Model Fit and Prediction</em> section, dynamic model parameters are evaluated at the time of model fitting and can depend on the number of observations in the fitted dataset. In the context of resampling, dynamic parameters are repeatedly evaluated at each fit of the resampled datasets. As such, their values can change based on the observations selected for training at each iteration of the resampling algorithm.</p>
<pre class="r"><code>## Dynamic model parameter k = log number of training set observations
resample(surv_fo, data = surv_df, model = CoxStepAICModel(k = .(log(nobs))))</code></pre>
</div>
<div id="model-comparisons" class="section level2">
<h2>Model Comparisons</h2>
<p>Resampled metrics from different models can be combined for comparison with the <code>Resamples</code> function. Optional names given on the left hand side of equal operators within calls to <code>Resamples</code> will be used as labels in output from the <code>summary</code> and <code>plot</code> functions. For comparisons of resampled output, the same control structure must be used in all associated calls to <code>resample</code> to ensure that resulting model metrics are computed on the same resampled training and test sets.</p>
<pre class="r"><code>## Resample estimation
res1 &lt;- resample(surv_fo, data = surv_df, model = GBMModel(n.trees = 25),
                 control = surv_means_control)
res2 &lt;- resample(surv_fo, data = surv_df, model = GBMModel(n.trees = 50),
                 control = surv_means_control)
res3 &lt;- resample(surv_fo, data = surv_df, model = GBMModel(n.trees = 100),
                 control = surv_means_control)

## Combine resample output for comparison
(res &lt;- Resamples(GBM1 = res1, GBM2 = res2, GBM3 = res3))
#&gt; Object of class &quot;Resamples&quot;
#&gt; 
#&gt; Models: GBM1, GBM2, GBM3
#&gt; Stratification variable: (strata) 
#&gt; 
#&gt; Object of class &quot;MLControl&quot;
#&gt; 
#&gt; Name: CVControl
#&gt; Label: K-Fold Cross-Validation
#&gt; Folds: 5
#&gt; Repeats: 3
#&gt; Seed: 123

summary(res)
#&gt; , , CIndex
#&gt; 
#&gt;           Mean    Median         SD       Min       Max NA
#&gt; GBM1 0.7122178 0.7014388 0.06433288 0.6289238 0.8386243  0
#&gt; GBM2 0.7058983 0.6883562 0.06256998 0.6300000 0.8359788  0
#&gt; GBM3 0.6941198 0.6762295 0.05933365 0.6244541 0.8227513  0

plot(res)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-46-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(res, type = &quot;density&quot;)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-46-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(res, type = &quot;errorbar&quot;)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-46-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(res, type = &quot;violin&quot;)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-46-4.png" width="672" style="display: block; margin: auto;" /></p>
<p>Pairwise model differences for each metric can be calculated with the <code>diff</code> function applied to results from a call to <code>Resamples</code>. Resulting differences can be summarized descriptively with the <code>summary</code> and <code>plot</code> functions and assessed for statistical significance with the <code>t.test</code> function.</p>
<pre class="r"><code>## Pairwise model comparisons
(perfdiff &lt;- diff(res))
#&gt; Object of class &quot;PerformanceDiff&quot;
#&gt; 
#&gt; Metrics: CIndex
#&gt; Models: GBM1 - GBM2, GBM1 - GBM3, GBM2 - GBM3

summary(perfdiff)
#&gt; , , CIndex
#&gt; 
#&gt;                    Mean      Median         SD         Min        Max NA
#&gt; GBM1 - GBM2 0.006319491 0.004366812 0.01613621 -0.02494062 0.03881279  0
#&gt; GBM1 - GBM3 0.018098015 0.019464720 0.02692342 -0.03026906 0.05479452  0
#&gt; GBM2 - GBM3 0.011778524 0.015267176 0.01695738 -0.01793722 0.04449153  0

plot(perfdiff)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-47-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>t.test(perfdiff)
#&gt; Object of class &quot;HTestPerformanceDiff&quot;
#&gt; 
#&gt; Upper diagonal: mean differences (row - column)
#&gt; Lower diagonal: p-values
#&gt; P-value adjustment method: holm
#&gt; 
#&gt; , , CIndex
#&gt; 
#&gt;            GBM1        GBM2       GBM3
#&gt; GBM1         NA 0.006319491 0.01809802
#&gt; GBM2 0.15157114          NA 0.01177852
#&gt; GBM3 0.05277722 0.052777218         NA</code></pre>
</div>
</div>
<div id="performance-analyses" class="section level1">
<h1>Performance Analyses</h1>
<div id="variable-importance" class="section level2">
<h2>Variable Importance</h2>
<p>The importance of variables in a model fit is estimated with the <code>varimp</code> function and plotted with <code>plot</code>. Variable importance is a measure of the relative importance of predictors in a model and has a default range of 0 to 100, where 0 denotes the least important variables and 100 the most.</p>
<pre class="r"><code>## Predictor variable importance
(vi &lt;- varimp(surv_fit))
#&gt;             Overall
#&gt; thickness 100.00000
#&gt; year       53.78039
#&gt; age        50.98203
#&gt; ulcer      20.00854
#&gt; sex         0.00000

plot(vi)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-49-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="calibration-curves" class="section level2">
<h2>Calibration Curves</h2>
<p>Agreement between model-predicted and observed values can be visualized with calibration curves. In the construction of these curves, cases are partitioned into bins according to their (resampled) predicted responses. Mean observed responses are then calculated within each of the bins and plotted on the vertical axis against the bin midpoints on the horizontal axis. An option to produce curves smoothed over the individual predicted values is also provided. Calibration curves that are close to the 45-degree line indicate close agreement between observed and predicted responses and a model that is said to be well calibrated.</p>
<pre class="r"><code>## Binned calibration curves
cal &lt;- calibration(res_probs, breaks = 10)
plot(cal, se = TRUE)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-50-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Smoothed calibration curves
cal &lt;- calibration(res_probs, breaks = NULL)
plot(cal)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-51-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="confusion-matrices" class="section level2">
<h2>Confusion Matrices</h2>
<p>Confusion matrices of cross-classified observed and predicted factor or survival probabilitie are available with the <code>confusion</code> function. They can be constructed with predicted class membership or with predicted class probabilities. In the latter case, predicted class membership is derived from predicted probabilities according to a probability cutoff value for binary factors and according to the class with highest probability for factors with more than two levels. Performance metrics, such as those described earlier for binary factors, can be computed with the <code>performance</code> function and summarized with <code>summary</code> and <code>plot</code>.</p>
<pre class="r"><code>## Confusion matrices
(conf &lt;- confusion(res_probs, cutoff = 0.5))
#&gt; GBMModel.time1 :
#&gt;          Observed
#&gt; Predicted         0         1
#&gt;         0 414.44407 112.55593
#&gt;         1  35.89744  52.10256
#&gt; 
#&gt; GBMModel.time2 :
#&gt;          Observed
#&gt; Predicted         0         1
#&gt;         0 258.77147 141.22853
#&gt;         1  82.75981 132.24019

performance(conf, metrics = c(&quot;Accuracy&quot; = accuracy,
                              &quot;Sensitivity&quot; = sensitivity,
                              &quot;Specificity&quot; = specificity))
#&gt; GBMModel.time1 :
#&gt;    Accuracy Sensitivity Specificity 
#&gt;   0.7586124   0.3164280   0.9202884 
#&gt; 
#&gt; GBMModel.time2 :
#&gt;    Accuracy Sensitivity Specificity 
#&gt;   0.6357913   0.4835661   0.7576801

summary(conf)
#&gt; GBMModel.time1 :
#&gt; Number of responses: 615
#&gt; Accuracy (SE): 0.7586124 (0.01725559)
#&gt; Majority class: 0.7322626
#&gt; Kappa: 0.2777282
#&gt; 
#&gt;                     0          1
#&gt; Observed    0.7322626 0.26773739
#&gt; Predicted   0.8569106 0.14308943
#&gt; Agreement   0.6738928 0.08471962
#&gt; Sensitivity 0.9202884 0.31642804
#&gt; Specificity 0.3164280 0.92028841
#&gt; PPV         0.7864214 0.59207459
#&gt; NPV         0.5920746 0.78642139
#&gt; 
#&gt; GBMModel.time2 :
#&gt; Number of responses: 615
#&gt; Accuracy (SE): 0.6357913 (0.01940416)
#&gt; Majority class: 0.5553354
#&gt; Kappa: 0.2464976
#&gt; 
#&gt;                     0         1
#&gt; Observed    0.5553354 0.4446646
#&gt; Predicted   0.6504065 0.3495935
#&gt; Agreement   0.4207666 0.2150247
#&gt; Sensitivity 0.7576801 0.4835661
#&gt; Specificity 0.4835661 0.7576801
#&gt; PPV         0.6469287 0.6150706
#&gt; NPV         0.6150706 0.6469287</code></pre>
<pre class="r"><code>plot(conf)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-53-1.png" width="672" style="display: block; margin: auto;" /><img src="using_files/figure-html/unnamed-chunk-53-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="partial-dependence-plots" class="section level2">
<h2>Partial Dependence Plots</h2>
<p>Partial dependence plots display the marginal effects of predictors on the response variable. The response scale displayed in the plots will depend on the response type: probability for predicted factors and survival probabilities, original scale for numerics, and survival time for predicted survival means.</p>
<pre class="r"><code>## Partial dependence plots
pd &lt;- dependence(surv_fit, select = c(thickness, age))
plot(pd)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-54-1.png" width="672" style="display: block; margin: auto;" /><img src="using_files/figure-html/unnamed-chunk-54-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="performance-curves" class="section level2">
<h2>Performance Curves</h2>
<p>Tradeoffs between correct and incorrect classifications of binary outcomes, across the range of possible cutoff probabilities, can be studied with performance curves.</p>
<div id="roc" class="section level3">
<h3>ROC</h3>
<p>Receiver operating characteristic (ROC) curves are one example in which true positive rates (sensitivity) are plotted against false positive rates (1 - specificity). Area under resulting ROC curves can be computed as an overall measure of model predictive performance and interpreted as the probability that a randomly selected event case will have a higher predicted value than a randomly selected non-event case.</p>
<pre class="r"><code>## ROC curves
roc &lt;- performance_curve(res_probs)
plot(roc, diagonal = TRUE)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-55-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(roc, type = &quot;cutoffs&quot;)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-55-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>auc(roc)
#&gt; Model: GBMModel.time1
#&gt; [1] 0.7216004
#&gt; -------------------------------------------------------- 
#&gt; Model: GBMModel.time2
#&gt; [1] 0.6696165</code></pre>
</div>
<div id="precision-recall" class="section level3">
<h3>Precision Recall</h3>
<p>In general, any two binary response metrics may be specified for the construction of a performance curve. Precision recall curves are another example.</p>
<pre class="r"><code>## Precision recall curves
pr &lt;- performance_curve(res_probs, metrics = c(precision, recall))
plot(pr)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-57-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>auc(pr)
#&gt; Model: GBMModel.time1
#&gt; [1] 0.43682
#&gt; -------------------------------------------------------- 
#&gt; Model: GBMModel.time2
#&gt; [1] 0.5887828</code></pre>
</div>
<div id="lift" class="section level3">
<h3>Lift</h3>
<p>Lift curves depict the rate at which observed binary responses are identifiable from (resampled) predicted response probabilities. In particular, they plot the true positive findings (sensitivity) against the positive test rates for all possible classification probability cutoffs. Accordingly, a lift curve can be interpreted as the rate at which positive responses are found as a function of the positive test rate among cases.</p>
<pre class="r"><code>## Lift curves
lf &lt;- lift(res_probs)
plot(lf, find = 0.75)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-59-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="modeling-strategies" class="section level1">
<h1>Modeling Strategies</h1>
<div id="model-tuning" class="section level2">
<h2>Model Tuning</h2>
<p>Many of the modeling functions have arguments, or parameters, that control aspects of their model fitting algorithms. For example, <code>GBMModel</code> parameters <code>n.trees</code> and <code>interaction.depth</code> control the number of decision trees to fit and the maximum depth of variable interactions. The <code>tune</code> function performs model fitting over a grid of parameter values and returns the model with the most optimal values. Optimality is determined based on the first performance metric supplied to the <code>metrics</code> argument of <code>tune</code>. Furthermore, argument <code>grid</code> controls the construction of grid values and can be a single numeric value giving the grid length in each parameter dimension, a call to <code>Grid</code> with the grid <code>length</code> and number of grid points to sample at <code>random</code>, or a user-specified data frame of grid points. Summary statistics and plots of resulting performances across all metrics and tuning parameters can be obtained with the <code>summary</code> and <code>plot</code> functions.</p>
<pre class="r"><code>## Tune over automatic grid of model parameters
(surv_tune &lt;- tune(surv_fo, data = surv_df, model = GBMModel,
                   grid = 3,
                   control = surv_means_control,
                   metrics = c(&quot;CIndex&quot; = cindex, &quot;RMSE&quot; = rmse)))
#&gt; Object of class &quot;MLModelTune&quot;
#&gt; 
#&gt; Model name: GBMModel
#&gt; Label: Generalized Boosted Regression
#&gt; Packages: gbm
#&gt; Response types: factor, numeric, Surv
#&gt; 
#&gt; Parameters:
#&gt; $n.trees
#&gt; [1] 50
#&gt; 
#&gt; $interaction.depth
#&gt; [1] 1
#&gt; 
#&gt; $n.minobsinnode
#&gt; [1] 10
#&gt; 
#&gt; $shrinkage
#&gt; [1] 0.1
#&gt; 
#&gt; $bag.fraction
#&gt; [1] 0.5
#&gt; 
#&gt; Grid:
#&gt;   n.trees interaction.depth
#&gt; 1      50                 1
#&gt; 2     100                 1
#&gt; 3     150                 1
#&gt; 4      50                 2
#&gt; 5     100                 2
#&gt; 6     150                 2
#&gt; 7      50                 3
#&gt; 8     100                 3
#&gt; 9     150                 3
#&gt; 
#&gt; Object of class &quot;Performance&quot;
#&gt; 
#&gt; Metrics: CIndex, RMSE
#&gt; Models: GBMModel.1, GBMModel.2, GBMModel.3, GBMModel.4, GBMModel.5, GBMModel.6, GBMModel.7, GBMModel.8, GBMModel.9 
#&gt; 
#&gt; Selected (CIndex): GBMModel.1

summary(surv_tune)
#&gt; , , CIndex
#&gt; 
#&gt;                 Mean    Median         SD       Min       Max NA
#&gt; GBMModel.1 0.7058983 0.6883562 0.06256998 0.6300000 0.8359788  0
#&gt; GBMModel.2 0.6941198 0.6762295 0.05933365 0.6244541 0.8227513  0
#&gt; GBMModel.3 0.6850918 0.6745843 0.06864062 0.5805085 0.8174603  0
#&gt; GBMModel.4 0.6961474 0.6886792 0.05489630 0.6207627 0.8028504  0
#&gt; GBMModel.5 0.6828937 0.6792453 0.06191098 0.5677966 0.8015873  0
#&gt; GBMModel.6 0.6785267 0.6933962 0.06486174 0.5868644 0.7885986  0
#&gt; GBMModel.7 0.6925677 0.6721311 0.05600214 0.6165254 0.8004751  0
#&gt; GBMModel.8 0.6778869 0.6650943 0.05688398 0.5889831 0.7838480  0
#&gt; GBMModel.9 0.6709213 0.6745283 0.06440546 0.5805085 0.8028504  0
#&gt; 
#&gt; , , RMSE
#&gt; 
#&gt;                Mean   Median       SD      Min       Max NA
#&gt; GBMModel.1 4622.523 4620.080 1536.488 2625.016  8292.560  0
#&gt; GBMModel.2 4828.093 4905.842 1455.894 2847.789  7503.051  0
#&gt; GBMModel.3 4984.213 5181.052 1548.834 2124.061  7327.174  0
#&gt; GBMModel.4 4785.732 4823.784 1644.107 2669.812  7365.786  0
#&gt; GBMModel.5 4396.219 4235.812 1723.906 1886.119  7491.740  0
#&gt; GBMModel.6 3810.610 4116.190 1476.657 1772.266  6017.007  0
#&gt; GBMModel.7 5013.930 4504.273 1766.908 2760.226  9407.171  0
#&gt; GBMModel.8 4984.817 4944.546 2052.461 1831.480  8473.961  0
#&gt; GBMModel.9 5213.172 4556.378 2745.462 2307.150 12983.578  0

plot(surv_tune, type = &quot;line&quot;)</code></pre>
<p><img src="using_files/figure-html/unnamed-chunk-60-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Tune over randomly sampled grid points
tune(surv_fo, data = surv_df, model = GBMModel,
     grid = Grid(length = 100, random = 10),
     control = surv_means_control)

## Tune over user-specified grid points
tune(surv_fo, data = surv_df, model = GBMModel,
     grid = expand.grid(n.trees = c(25, 50, 100),
                        interaction.depth = 1:3),
     control = surv_means_control)</code></pre>
<p>The return value of <code>tune</code> is a model object with the optimal tuning parameters and not a model fit object. The returned model can be fit subsequently to a set of data with the <code>fit</code> function.</p>
<pre class="r"><code>## Fit the tuned model
surv_fit &lt;- fit(surv_fo, data = surv_df, model = surv_tune)
(vi &lt;- varimp(surv_fit))
#&gt;             Overall
#&gt; thickness 100.00000
#&gt; age        66.54478
#&gt; ulcer      34.04836
#&gt; year       12.62582
#&gt; sex         0.00000</code></pre>
</div>
<div id="model-selection" class="section level2">
<h2>Model Selection</h2>
<p>Model selection can be performed with the <code>tune</code> function to select from any combination of models and model parameters. It has as a special case the just-discussed tuning of a single model over a grid of parameter values. In general, a list containing any combination of model functions, function names, and function calls can be supplied to the <code>models</code> argument of <code>tune</code> to perform model selection. An <code>expand.model</code> helper function is additionally provided to expand a model over a grid of tuning parameters for inclusion in the list if so desired. In this general form of model selection, the <code>grid</code> argument discussed previously for grid tuning is not used.</p>
<pre class="r"><code>## Select from a list of candidate models
model_list &lt;- c(
  expand.model(GBMModel, n.trees = c(50, 100), interaction.depth = 1:2),
  GLMNetModel(lambda = 0.01),
  CoxModel,
  SurvRegModel
)

tune(surv_fo, data = surv_df, models = model_list,
     control = surv_means_control)</code></pre>
</div>
<div id="ensemble-models" class="section level2">
<h2>Ensemble Models</h2>
<p>Ensemble methods combine multiple base learning algorithms as a strategy to improve predictive performance. Two ensemble methods implemented in <code>Machineshop</code> are <em>stacked regression</em> <span class="citation">(Breiman 1996)</span> and <em>super learners</em> <span class="citation">(van der Lann and Hubbard 2007)</span>. Stacked regression fits a linear combination of resampled predictions from specified base learners; whereas, super learners fit a specified model, such as <code>GBMModel</code>, to the base learner predictions and optionally also to the original predictor variables. Illustrated below is a performance evaluation of stacked regression and a super learner fit to gradient boosted, random forest, and Cox regression base learners. In the second case, a separate gradient boosted model is used as the super learner.</p>
<pre class="r"><code>## Stacked regression
stackedmodel &lt;- StackedModel(GLMBoostModel, CForestModel, CoxModel)
res_stacked &lt;- resample(surv_fo, data = surv_df, model = stackedmodel)
summary(res_stacked)
#&gt;             Mean    Median        SD  Min       Max NA
#&gt; CIndex 0.6847059 0.7261905 0.1185994 0.44 0.8198198  0

## Super learner
supermodel &lt;- SuperModel(GLMBoostModel, CForestModel, CoxModel,
                         model = GBMModel)
res_super &lt;- resample(surv_fo, data = surv_df, model = supermodel)
summary(res_super)
#&gt;             Mean    Median         SD       Min       Max NA
#&gt; CIndex 0.7060767 0.7133354 0.09206905 0.4960317 0.8138298  0</code></pre>
</div>
</div>
<div id="package-extensions" class="section level1">
<h1>Package Extensions</h1>
<p>Custom models and metrics can be defined with the <code>MLModel</code> and <code>MLMetric</code> constructors for use with the model fitting, prediction, and performance assessment tools provided by the package.</p>
<pre class="r"><code>## Logistic regression model
LogisticModel &lt;- MLModel(
  name = &quot;LogisticModel&quot;,
  types = &quot;binary&quot;,
  fit = function(formula, data, weights, ...) {
    glm(formula, data = data, weights = weights, family = binomial, ...)
  },
  predict = function(object, newdata, ...) {
    predict(object, newdata = newdata, type = &quot;response&quot;)
  },
  varimp = function(object, ...) {
    pchisq(coef(object)^2 / diag(vcov(object)), 1)
  }
)

## F2 score metric
f2_score &lt;- MLMetric(
  function(observed, predicted, ...) {
    f_score(observed, predicted, beta = 2, ...)
  },
  name = &quot;f2_score&quot;,
  label = &quot;F2 Score&quot;,
  maximize = TRUE
)

library(MASS)
res &lt;- resample(type ~ ., data = Pima.tr, model = LogisticModel)
summary(performance(res, metric = f2_score))
#&gt;               Mean    Median        SD       Min       Max NA
#&gt; f2_score 0.5697769 0.6060606 0.1924873 0.1666667 0.8571429  0</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-andersen:1993:SMB">
<p>Andersen, Per K, Ornulf Borgan, Richard D Gill, and Niels Keiding. 1993. <em>Statistical Models Based on Counting Processes</em>. New York: Springer.</p>
</div>
<div id="ref-bache:2014:MFP">
<p>Bache, Stefan Milton, and Hadley Wickham. 2014. <em>magrittr: A Forward-Pipe Operator for R</em>. <a href="https://CRAN.R-project.org/package=magrittr">https://CRAN.R-project.org/package=magrittr</a>.</p>
</div>
<div id="ref-breiman:1996:SR">
<p>Breiman, Leo. 1996. “Stacked Regression.” <em>Machine Learning</em> 24: 49–64.</p>
</div>
<div id="ref-breslow:1972:DPC">
<p>Breslow, Norman E. 1972. “Discussion of Professor Cox’s Paper.” <em>Journal of the Royal Statistical Society, Series B</em> 34: 216–17.</p>
</div>
<div id="ref-efron:1967:PFB">
<p>Efron, Bradley. 1967. “The Two Sample Problem with Censored Data.” In <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 4: Biology and Problems of Health</em>, 831–53. Berkeley, California: University of California Press.</p>
</div>
<div id="ref-efron:1977:ECL">
<p>———. 1977. “The Efficiency of Cox’s Likelihood Function for Censored Data.” <em>Journal of the American Statistical Association</em> 72 (359): 557–65.</p>
</div>
<div id="ref-fleming:1984:NES">
<p>Fleming, Thomas R, and David P Harrington. 1984. “Nonparametric Estimation of the Survival Distribution in Censored Data.” <em>Communications in Statistics - Theory and Methods</em> 13 (20): 2469–86.</p>
</div>
<div id="ref-graf:1999:ACP">
<p>Graf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher. 1999. “Assessment and Comparison of Prognostic Classification Schemes for Survival Data.” <em>Statistics in Medicine</em> 18 (17–18): 2529–45.</p>
</div>
<div id="ref-harrell:1982:EYM">
<p>Harrell, Frank E, Robert M Califf, David B Pryor, Kerry L Lee, and Robert A Rosati. 1982. “Evaluating the Yield of Medical Tests.” <em>JAMA</em> 247 (18): 2543–6.</p>
</div>
<div id="ref-heagerty:2004:TDR">
<p>Heagerty, Patrick J, Thomas Lumley, and Margaret S Pepe. 2004. “Time-Dependent ROC Curves for Censored Survival Data and a Diagnostic Marker.” <em>Biometrics</em> 56 (2): 337–44.</p>
</div>
<div id="ref-kuhn:2018:RPT">
<p>Kuhn, Max, and Hadley Wickham. 2018. <em>recipes: Preprocessing Tools to Create Design Matrices</em>. <a href="https://CRAN.R-project.org/package=recipes">https://CRAN.R-project.org/package=recipes</a>.</p>
</div>
<div id="ref-microsoft:2017:FPF">
<p>Microsoft, and Steve Weston. 2017. <em>foreach: Provides Foreach Looping Construct for R</em>. <a href="https://CRAN.R-project.org/package=foreach">https://CRAN.R-project.org/package=foreach</a>.</p>
</div>
<div id="ref-microsoft:2017:DFP">
<p>———. 2018. <em>doParallel: Foreach Parallel Adaptor for the ’Parallel’ Package</em>. <a href="https://CRAN.R-project.org/package=doParallel">https://CRAN.R-project.org/package=doParallel</a>.</p>
</div>
<div id="ref-perkins:2006:IOC">
<p>Perkins, Neil J, and Enrique F Schisterman. 2006. “The Inconsistency of "Optimal" Cutpoints Obtained Using Two Criteria Based on the Receiver Operating Characteristic Curve.” <em>American Journal of Epidemiology</em> 163 (7): 670–75.</p>
</div>
<div id="ref-vanderLann:2007:SL">
<p>van der Lann, Mark J, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-youden:1950:IRD">
<p>Youden, William J. 1950. “Index for Rating Diagnostic Tests.” <em>Cancer</em> 3 (1): 32–35.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
